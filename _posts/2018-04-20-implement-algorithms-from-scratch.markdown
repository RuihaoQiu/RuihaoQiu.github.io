---
title: "Implement machine learning algorithms from scratch"
layout: post
date: 2018-04-20 11:48
image:
headerImage: false
tag:
- machine learning
- algorithm
- python
projects: true
hidden: true
category: project
author: Ruihao Qiu
---
<div class="breaker"></div>

Implement the most important algorithms for machine learning and searching from scratch.

#### **Machine learning**:

- [K-nearest neighbors (KNN)](https://github.com/RuihaoQiu/Algorithms/blob/master/KNearestNeighbor.ipynb)  
KNN just memorizes the data and make prediction by the majority vote of its K nearest neighbors.
- [Naive Bayes](https://github.com/RuihaoQiu/Algorithms/blob/master/NaiveBayes.ipynb)  
Naive Bayes assumes that all features in are independent, calculate the likelihood of each class from features based on Bayes Rule.
- [Decision tree](https://github.com/RuihaoQiu/Algorithms/blob/master/DecisionTree.ipynb)  
Decision tree make the prediction by answering a series of question for each features.
- [Random forest](https://github.com/RuihaoQiu/Algorithms/blob/master/RandomForest.ipynb)  
Random forest is an tree-based ensemble algorithm. It consists of numbers of decision trees, each tree is built on random subset of samples with random subset of features. The overall output is normally the majority vote of all trees.
- [Adaboost](https://github.com/RuihaoQiu/Algorithms/blob/master/Adaboost.ipynb)  
It is a sequential ensemble tree-base algorithm. It boost the overall performance by adding weak learners sequentially and put more weights on the misclassified samples by the previous learner.
- [Gradient boosting](https://github.com/RuihaoQiu/Algorithms/blob/master/GradientBoosting.ipynb)  
Gradient boosting, an powerful sequential tree-based learning algorithm. It is aim to boost the overall performance by sequentially updating the results with adding the prediction of each learner. Each learner is built by taking the gradient of the previous learner as the target variables.
- [Linear regression](https://github.com/RuihaoQiu/Algorithms/blob/master/LinearRegression.ipynb)  
Find the linear relation between X and continuous target variables y.
- [Logistic regression](https://github.com/RuihaoQiu/Algorithms/blob/master/LogisticRegression.ipynb)  
It is constructed by a linear regression and a logistic function
- [Neural network](https://github.com/RuihaoQiu/Algorithms/blob/master/NeuralNetwork.ipynb)  
Neural networks generally have multiple connected layers between their input and output, called “hidden” layers. There are numbers of neurons in each layer, each neuron receive the signals from those from the previous layer and process it to the next layer (Mathematically, the sum of weighted input followed by a activation function).

(to be continued … )

#### [Check the whole project here.](https://github.com/RuihaoQiu/Algorithms)
